{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlmQXVds1hmB"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "### Group Members:\n",
        "\n",
        "* Farhan Jamil\n",
        "* Shoaib Huq\n",
        "* Lerich Osay\n",
        "* Sriram Sendhil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq3wZecC1hmC"
      },
      "source": [
        "## Step 0: Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y6pR6ng1hmC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, Counter\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7bvxYV51hmC"
      },
      "source": [
        "## Step 1: Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyLRgFqB1hmC",
        "outputId": "65bbe527-9111-44f7-a0e3-6feaedf552f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2ed8638adb77>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mvalidation_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrain_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mtrain_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2ed8638adb77>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mEach\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mseparate\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.txt'"
          ]
        }
      ],
      "source": [
        "def load_data(filepath):\n",
        "    \"\"\"\n",
        "    Load data from a file and return a list of reviews.\n",
        "    Each line in the file is a separate review.\n",
        "    \"\"\"\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        reviews = f.readlines()\n",
        "    return reviews\n",
        "\n",
        "def preprocess(text):\n",
        "    \"\"\"\n",
        "    Preprocessing method:\n",
        "    - Convert to lowercase\n",
        "    - Handle punctuation better\n",
        "    - Add start/end sentence markers\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Replace specific punctuation with spaces\n",
        "    text = re.sub(r'[,.!?;:]', ' ', text)\n",
        "\n",
        "    # Replace multiple spaces with single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Strip leading/trailing whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    # Split by spaces to get tokens\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Add sentence boundary markers\n",
        "    tokens = ['<s>'] + tokens + ['</s>']\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def preprocess_corpus(reviews):\n",
        "    \"\"\"Preprocess all reviews in the corpus\"\"\"\n",
        "    all_tokens = []\n",
        "    for review in reviews:\n",
        "        tokens = preprocess(review)\n",
        "        all_tokens.extend(tokens)\n",
        "    return all_tokens\n",
        "\n",
        "# Load and preprocess data\n",
        "print(\"Loading and preprocessing data...\")\n",
        "train_path = 'train.txt'\n",
        "validation_path = 'val.txt'\n",
        "\n",
        "train_reviews = load_data(train_path)\n",
        "train_tokens = preprocess_corpus(train_reviews)\n",
        "\n",
        "validation_reviews = load_data(validation_path)\n",
        "validation_tokens = preprocess_corpus(validation_reviews)\n",
        "\n",
        "print(\"Some of the training set tokens:\\t\", train_tokens[:10])\n",
        "print(\"Some of the validation set tokens:\\t\", validation_tokens[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0FE19GY1hmD"
      },
      "source": [
        "## Step 2: Vocabulary Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p3NmH0F1hmD"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(tokens, min_count=1):\n",
        "    \"\"\"\n",
        "    Build vocabulary from tokens, optionally filtering by minimum count\n",
        "    \"\"\"\n",
        "    word_counts = Counter(tokens)\n",
        "    vocab = {word for word, count in word_counts.items() if count >= min_count}\n",
        "    return vocab\n",
        "\n",
        "print(\"Building vocabulary...\")\n",
        "vocab = build_vocabulary(train_tokens)\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Full vocabulary size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MguwxBI1hmD"
      },
      "source": [
        "## Step 3: Define Smoothing Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP_iGOKX1hmD"
      },
      "outputs": [],
      "source": [
        "def laplace_smoothing(counts, vocab_size, context_counts=None):\n",
        "    \"\"\"Laplace (add-1) smoothing.\"\"\"\n",
        "    smoothed_probs = {}\n",
        "\n",
        "    if context_counts is None:  # Unigram case\n",
        "        total_tokens = sum(counts.values())\n",
        "        for item, count in counts.items():\n",
        "            smoothed_probs[item] = (count + 1) / (total_tokens + vocab_size)\n",
        "    else:  # Bigram case\n",
        "        for (w1, w2), count in counts.items():\n",
        "            smoothed_probs[(w1, w2)] = (count + 1) / (context_counts[w1] + vocab_size)\n",
        "\n",
        "    return smoothed_probs\n",
        "\n",
        "def add_k_smoothing(counts, vocab_size, k=0.1, context_counts=None):\n",
        "    \"\"\"Add-k smoothing with custom k.\"\"\"\n",
        "    smoothed_probs = {}\n",
        "\n",
        "    if context_counts is None:  # Unigram case\n",
        "        total_tokens = sum(counts.values())\n",
        "        for item, count in counts.items():\n",
        "            smoothed_probs[item] = (count + k) / (total_tokens + k * vocab_size)\n",
        "    else:  # Bigram case\n",
        "        for (w1, w2), count in counts.items():\n",
        "            smoothed_probs[(w1, w2)] = (count + k) / (context_counts[w1] + k * vocab_size)\n",
        "\n",
        "    return smoothed_probs\n",
        "\n",
        "## define methods to count occurences of n-grams\n",
        "\n",
        "def get_unigram_counts(tokens):\n",
        "    \"\"\"Count occurrences of each word\"\"\"\n",
        "    unigram_counts = Counter(tokens)\n",
        "    return unigram_counts\n",
        "\n",
        "def get_bigram_counts(tokens):\n",
        "    \"\"\"Count occurrences of each word pair\"\"\"\n",
        "    bigram_counts = Counter(zip(tokens[:-1], tokens[1:]))\n",
        "    return bigram_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHhMTqzG1hmD"
      },
      "source": [
        "## Step 4: Define Methods to Handle Unknown Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy8rA-VN1hmD"
      },
      "outputs": [],
      "source": [
        "def replace_rare_words(tokens, min_count=2):\n",
        "    \"\"\"\n",
        "    Replace words that appear less than min_count times with <UNK> token.\n",
        "    Returns the modified tokens and a mapping of words to their replacement.\n",
        "    \"\"\"\n",
        "    word_counts = Counter(tokens)\n",
        "    replacement_map = {word: (word if count >= min_count else '<UNK>')\n",
        "                      for word, count in word_counts.items()}\n",
        "\n",
        "    replaced_tokens = [replacement_map.get(token, '<UNK>') for token in tokens]\n",
        "    return replaced_tokens, replacement_map\n",
        "\n",
        "def create_unk_vocabulary(tokens, replacement_map):\n",
        "    \"\"\"Create vocabulary with <UNK> token\"\"\"\n",
        "    unk_vocab = set(replacement_map.values())\n",
        "    return unk_vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Iqa-nRP1hmD"
      },
      "source": [
        "## Step 5: Define Language Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp_YQsMt1hmE"
      },
      "outputs": [],
      "source": [
        "## define methods to calculate perplexity for language models\n",
        "\n",
        "def calculate_unigram_perplexity(unigram_probs, test_tokens, p_zero=1e-10):\n",
        "    \"\"\"Calculate perplexity using unigram model with handling of unseen words\"\"\"\n",
        "    N = len(test_tokens)\n",
        "    log_prob_sum = 0\n",
        "\n",
        "    for token in test_tokens:\n",
        "        if token in unigram_probs:\n",
        "            prob = unigram_probs[token]\n",
        "        else:\n",
        "            # Use probability for unseen words\n",
        "            prob = p_zero\n",
        "\n",
        "        # Avoid log(0) by imposing a minimum probability\n",
        "        prob = max(prob, 1e-10)\n",
        "        log_prob_sum += np.log2(prob)\n",
        "\n",
        "    perplexity = 2 ** (-log_prob_sum / N)\n",
        "    return perplexity\n",
        "\n",
        "def calculate_bigram_perplexity(bigram_probs, unigram_probs, test_tokens, p_zero=1e-10):\n",
        "    \"\"\"Calculate perplexity using bigram model with backing off\"\"\"\n",
        "    N = len(test_tokens) - 1  # Number of bigrams\n",
        "    log_prob_sum = 0\n",
        "\n",
        "    for i in range(N):\n",
        "        bigram = (test_tokens[i], test_tokens[i+1])\n",
        "\n",
        "        if bigram in bigram_probs:\n",
        "            prob = bigram_probs[bigram]\n",
        "        elif test_tokens[i+1] in unigram_probs:\n",
        "            # Back off to unigram\n",
        "            prob = unigram_probs[test_tokens[i+1]]\n",
        "        else:\n",
        "            # Use probability for unseen words\n",
        "            prob = p_zero\n",
        "\n",
        "        # Avoid log(0)\n",
        "        prob = max(prob, 1e-10)\n",
        "        log_prob_sum += np.log2(prob)\n",
        "\n",
        "    perplexity = 2 ** (-log_prob_sum / N)\n",
        "    return perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMG_I4hP1hmE"
      },
      "source": [
        "## Step 6: Handle Unknown Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5L0PnGT1hmE"
      },
      "outputs": [],
      "source": [
        "# Try different thresholds for handling rare words\n",
        "min_counts = [1, 2, 3, 5]\n",
        "results = {}\n",
        "\n",
        "for min_count in min_counts:\n",
        "    print(f\"\\nTesting with minimum count threshold: {min_count}\")\n",
        "\n",
        "    # Replace rare words with <UNK>\n",
        "    train_tokens_with_unk, replacement_map = replace_rare_words(train_tokens, min_count=min_count)\n",
        "    unk_vocab = create_unk_vocabulary(train_tokens, replacement_map)\n",
        "    unk_vocab_size = len(unk_vocab)\n",
        "    print(f\"Vocabulary size with <UNK> (min_count={min_count}): {unk_vocab_size}\")\n",
        "\n",
        "    # Apply the same replacement to validation tokens\n",
        "    validation_tokens_with_unk = [replacement_map.get(token, '<UNK>') for token in validation_tokens]\n",
        "\n",
        "    # Count n-grams\n",
        "    unigram_counts_unk = get_unigram_counts(train_tokens_with_unk)\n",
        "    bigram_counts_unk = get_bigram_counts(train_tokens_with_unk)\n",
        "\n",
        "    # Apply Laplace (add-1) smoothing\n",
        "    print(\"Applying Laplace smoothing...\")\n",
        "    unigram_laplace = laplace_smoothing(unigram_counts_unk, unk_vocab_size)\n",
        "    bigram_laplace = laplace_smoothing(bigram_counts_unk, unk_vocab_size, context_counts=unigram_counts_unk)\n",
        "\n",
        "    # Apply add-k smoothing with k=0.1\n",
        "    print(\"Applying add-k smoothing...\")\n",
        "    unigram_add_k = add_k_smoothing(unigram_counts_unk, unk_vocab_size, k=0.1)\n",
        "    bigram_add_k = add_k_smoothing(bigram_counts_unk, unk_vocab_size, k=0.1, context_counts=unigram_counts_unk)\n",
        "\n",
        "    # Calculate perplexities\n",
        "    print(\"Calculating perplexities...\")\n",
        "    perplexities = {\n",
        "        f\"Laplace Unigram (min_count={min_count})\":\n",
        "            calculate_unigram_perplexity(unigram_laplace, validation_tokens_with_unk),\n",
        "        f\"Laplace Bigram (min_count={min_count})\":\n",
        "            calculate_bigram_perplexity(bigram_laplace, unigram_laplace, validation_tokens_with_unk),\n",
        "        f\"Add-k (k=0.1) Unigram (min_count={min_count})\":\n",
        "            calculate_unigram_perplexity(unigram_add_k, validation_tokens_with_unk),\n",
        "        f\"Add-k (k=0.1) Bigram (min_count={min_count})\":\n",
        "            calculate_bigram_perplexity(bigram_add_k, unigram_add_k, validation_tokens_with_unk),\n",
        "    }\n",
        "\n",
        "    # Save results\n",
        "    results.update(perplexities)\n",
        "\n",
        "    # Display current results\n",
        "    for model, perplexity in perplexities.items():\n",
        "        print(f\"{model}: {perplexity:.2f}\")\n",
        "\n",
        "# Find the best min_count setting\n",
        "best_min_count = min(min_counts, key=lambda x: results[f\"Add-k (k=0.1) Bigram (min_count={x})\"])\n",
        "print(f\"\\nExperimenting with different k values using min_count={best_min_count}...\")\n",
        "\n",
        "# Get tokens with the best min_count\n",
        "train_tokens_with_unk, replacement_map = replace_rare_words(train_tokens, min_count=best_min_count)\n",
        "validation_tokens_with_unk = [replacement_map.get(token, '<UNK>') for token in validation_tokens]\n",
        "unk_vocab = create_unk_vocabulary(train_tokens, replacement_map)\n",
        "unk_vocab_size = len(unk_vocab)\n",
        "\n",
        "# Get counts\n",
        "unigram_counts_unk = get_unigram_counts(train_tokens_with_unk)\n",
        "bigram_counts_unk = get_bigram_counts(train_tokens_with_unk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWjjSIz-1hmE"
      },
      "source": [
        "## Step 7: Test Language Models' Perplexity with Different Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-wuNdu81hmE"
      },
      "outputs": [],
      "source": [
        "k_values = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0]\n",
        "k_results = {}\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"Testing add-k with k={k}...\")\n",
        "    unigram_add_k = add_k_smoothing(unigram_counts_unk, unk_vocab_size, k=k)\n",
        "    bigram_add_k = add_k_smoothing(bigram_counts_unk, unk_vocab_size, k=k, context_counts=unigram_counts_unk)\n",
        "\n",
        "    unigram_perp = calculate_unigram_perplexity(unigram_add_k, validation_tokens_with_unk)\n",
        "    bigram_perp = calculate_bigram_perplexity(bigram_add_k, unigram_add_k, validation_tokens_with_unk)\n",
        "\n",
        "    k_results[f\"Add-{k} Unigram\"] = unigram_perp\n",
        "    k_results[f\"Add-{k} Bigram\"] = bigram_perp\n",
        "\n",
        "    print(f\"Add-{k} Unigram perplexity: {unigram_perp:.2f}\")\n",
        "    print(f\"Add-{k} Bigram perplexity: {bigram_perp:.2f}\")\n",
        "\n",
        "# Find the best k value\n",
        "best_k_unigram = min([(k, k_results[f\"Add-{k} Unigram\"]) for k in k_values], key=lambda x: x[1])\n",
        "best_k_bigram = min([(k, k_results[f\"Add-{k} Bigram\"]) for k in k_values], key=lambda x: x[1])\n",
        "\n",
        "print(\"\\nBest k value for Unigram model:\")\n",
        "print(f\"k = {best_k_unigram[0]}, Perplexity = {best_k_unigram[1]:.2f}\")\n",
        "\n",
        "print(\"\\nBest k value for Bigram model:\")\n",
        "print(f\"k = {best_k_bigram[0]}, Perplexity = {best_k_bigram[1]:.2f}\")\n",
        "\n",
        "# Compare Laplace (add-1) with the best add-k\n",
        "best_k = best_k_bigram[0]  # Use best k from bigram model for comparison\n",
        "print(f\"\\nComparing Laplace (add-1) with best Add-k (k={best_k})...\")\n",
        "\n",
        "# Apply best add-k smoothing\n",
        "best_unigram_add_k = add_k_smoothing(unigram_counts_unk, unk_vocab_size, k=best_k)\n",
        "best_bigram_add_k = add_k_smoothing(bigram_counts_unk, unk_vocab_size, k=best_k, context_counts=unigram_counts_unk)\n",
        "\n",
        "# Apply Laplace smoothing\n",
        "unigram_laplace = laplace_smoothing(unigram_counts_unk, unk_vocab_size)\n",
        "bigram_laplace = laplace_smoothing(bigram_counts_unk, unk_vocab_size, context_counts=unigram_counts_unk)\n",
        "\n",
        "# Calculate perplexities\n",
        "laplace_uni_perp = calculate_unigram_perplexity(unigram_laplace, validation_tokens_with_unk)\n",
        "laplace_bi_perp = calculate_bigram_perplexity(bigram_laplace, unigram_laplace, validation_tokens_with_unk)\n",
        "best_k_uni_perp = calculate_unigram_perplexity(best_unigram_add_k, validation_tokens_with_unk)\n",
        "best_k_bi_perp = calculate_bigram_perplexity(best_bigram_add_k, best_unigram_add_k, validation_tokens_with_unk)\n",
        "\n",
        "print(f\"Laplace Unigram perplexity: {laplace_uni_perp:.2f}\")\n",
        "print(f\"Laplace Bigram perplexity: {laplace_bi_perp:.2f}\")\n",
        "print(f\"Best Add-k Unigram perplexity (k={best_k}): {best_k_uni_perp:.2f}\")\n",
        "print(f\"Best Add-k Bigram perplexity (k={best_k}): {best_k_bi_perp:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCTfDdD71hmE"
      },
      "source": [
        "## Vizualizing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq2SiFWC1hmE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot([float(k) for k in k_values],\n",
        "         [k_results[f\"Add-{k} Unigram\"] for k in k_values], 'o-', label='Unigram')\n",
        "plt.plot([float(k) for k in k_values],\n",
        "         [k_results[f\"Add-{k} Bigram\"] for k in k_values], 'o-', label='Bigram')\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.title('Effect of k value on Perplexity for Add-k Smoothing')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xscale('log')  # Log scale for better visualization of small k values\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize comparison\n",
        "plt.figure(figsize=(8, 6))\n",
        "models = ['Unigram', 'Bigram']\n",
        "laplace_perps = [laplace_uni_perp, laplace_bi_perp]\n",
        "best_k_perps = [best_k_uni_perp, best_k_bi_perp]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "plt.bar(x - width/2, laplace_perps, width, label=f'Laplace (k=1)')\n",
        "plt.bar(x + width/2, best_k_perps, width, label=f'Best Add-k (k={best_k})')\n",
        "\n",
        "plt.xlabel('Model Type')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.title('Comparison of Laplace and Best Add-k Smoothing')\n",
        "plt.xticks(x, models)\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}